{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO0uDicyj7IOtbH3D5ByD35",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/muntazirabidi/machine_learning_tutorials/blob/main/multiclass_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multiclass Classification"
      ],
      "metadata": {
        "id": "fSz_Wjy3e63B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multiclass classification is the task of classifying instances into one of three or more classes. For example, classifying a set of images as \"dog,\" \"cat,\" \"bird,\" or \"fish\" would be a multiclass classification problem.\n",
        "\n",
        "There are several approaches to multiclass classification, including one-versus-all and one-versus-one. In one-versus-all (OVA) classification, a separate binary classifier is trained for each class, with the class being classified as \"positive\" and all other classes as \"negative.\" For example, in the \"dog,\" \"cat,\" \"bird,\" \"fish\" classification problem, four classifiers would be trained: one to distinguish dogs from non-dogs, one to distinguish cats from non-cats, one to distinguish birds from non-birds, and one to distinguish fish from non-fish.\n",
        "\n",
        "In one-versus-one (OVO) classification, a binary classifier is trained for every pair of classes. For the \"dog,\" \"cat,\" \"bird,\" \"fish\" classification problem, this would result in six classifiers being trained: one to distinguish dogs from cats, one to distinguish dogs from birds, one to distinguish dogs from fish, one to distinguish cats from birds, one to distinguish cats from fish, and one to distinguish birds from fish.\n",
        "\n",
        "There are pros and cons to both approaches. OVA can be more efficient, as it requires training fewer classifiers, but it can be less effective if the \"negative\" class is highly diverse. OVO requires training more classifiers, but each classifier only has to distinguish between two classes, which can make it more effective.\n",
        "\n",
        "> Some algorithms (such as Support Vector Machine classifiers) scale poorly with the size of the training set. For these algorithms OvO is preferred because it is faster to train many classifiers on small training sets than to train few classifiers on large training sets. For most binary classification algorithms OvR is preffered. \n",
        "\n",
        "\n",
        "Scikit-Learn detects when you try to use a binary classification algorithms for a multi-class classification task, and it automatically runs OvR or OvO depending on the algorithm. Lets try this with SVM. We first load the MNIST data and split it into test and train datasets."
      ],
      "metadata": {
        "id": "F-7ZKQP0e9hN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "import numpy as np\n",
        "from IPython.display import set_matplotlib_formats\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "\n",
        "mnist = fetch_openml('mnist_784', version=1)\n",
        "X, y = mnist['data'], mnist['target']\n",
        "y=y.astype(np.uint8)\n",
        "X_train, X_test, y_train, y_test = X.to_numpy()[:60000], X.to_numpy()[60000:], y.to_numpy()[:60000], y.to_numpy()[60000:]\n"
      ],
      "metadata": {
        "id": "JqoWxPjviJV6"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHJMOjUCe0vc",
        "outputId": "b60c5148-3fff-4a83-fff9-e3c532f3cccb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "svm_clf = SVC()\n",
        "svm_clf.fit(X_train, y_train)\n",
        "\n",
        "some_digit = X.to_numpy()[0] # some digit\n",
        "svm_clf.predict([some_digit])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "some_digit_scores = svm_clf.decision_function([some_digit])\n",
        "some_digit_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrM3ydTye6CM",
        "outputId": "d794cb75-53ac-4045-e642-9569ce3ab78c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.72501977,  2.72809088,  7.2510018 ,  8.3076379 , -0.31087254,\n",
              "         9.3132482 ,  1.70975103,  2.76765202,  6.23049537,  4.84771048]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.argmax(some_digit_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JdHV8Wbk9NN",
        "outputId": "48b958b2-020a-4a8e-b604-22dc75799cdd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "svm_clf.classes_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qL_cCJ0QlJyz",
        "outputId": "2fd9bba4-6c97-4e83-da18-34730e6783a7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "svm_clf.classes_[5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYcIt8WrlML_",
        "outputId": "d7086f9d-402c-484b-aae4-442eab466689"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "ovr_clf = OneVsRestClassifier(SVC())\n",
        "ovr_clf.fit(X_train, y_train)\n",
        "ovr_clf.predict([some_digit])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OKxYIRina5e",
        "outputId": "2df6fdbc-4b55-4a6f-bcef-a8c09b1376d8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "sgd_clf = SGDClassifier(random_state=42)\n",
        "\n",
        "sgd_clf.fit(X_train, y_train)\n",
        "sgd_clf.predict([some_digit])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_xyhZVanvyH",
        "outputId": "18998798-28bd-43dc-a6f0-25dcd25eb93d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# simply scaling the input can increase the accuracy.\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled =scaler.fit_transform(X_train.astype(np.float64))\n",
        "cross_val_score(sgd_clf, X_train_scaled, y_train, cv=3, scoring = 'accuracy')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cl5Mr7CmlzC",
        "outputId": "8b626d65-99d8-4ee1-9923-4e8c833738dc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.8983, 0.891 , 0.9018])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Error Analysis\n",
        "In ML project one should start with exploring sdata preparation, try out multiple models, shortlisitng the best ones and fine-tune their hyperparameters using `GridSearchCV` and automate as much as possible. Now you have found a promising model and want to improve it. One way to do it is to analyse the types of errors it makes. First look at the confusion martrix"
      ],
      "metadata": {
        "id": "UhamMihHlXOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "\n",
        "y_train_pred = cross_val_predict(sgd_clf, X_train_scaled, y_train, cv=3)\n",
        "conf_mx = confusion_matrix(y_train, y_train_pred)\n",
        "\n",
        "conf_mx"
      ],
      "metadata": {
        "id": "lRTZCAwllPKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w6tnBv3MlaCx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}